{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file='../openai_api_key.txt'\n",
    "with open(key_file, 'r') as file:\n",
    "    openai_api_key=file.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "# This simple prompt simulates the case of accessing private information.\n",
    "concealedinfo_prompt = PromptTemplate.from_template(\"Mary is 24. Given this information, answer the following question: {question}\")\n",
    "concealedinfo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=concealedinfo_prompt, verbose=verbose)\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "calculate_chain = LLMMathChain.from_llm(llm=OpenAI(temperature=0), verbose=verbose) \n",
    "\n",
    "tools=[ wiki_tool,\n",
    "        Tool(\n",
    "            name=\"CALCULATE\",\n",
    "            func=calculate_chain.run, \n",
    "            description=\"Useful for making math calculations. Input: a calculation to perform on a set of numbers (these need to be numbers, not literal expressions). Outputs: the result of the calculation.\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"INFO_ABOUT_MARY\",\n",
    "            func=concealedinfo_chain.run,\n",
    "            description='Only needed to answer a question that requires knowledge about Mary. Do not use unless Mary is involved.' \n",
    "        ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM temperature will be set to a non-zero value in order to have slightly different responses later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\") # To see the prompt in full: https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-1106',temperature=0.1)\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=verbose, return_intermediate_steps=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will invoke the agent different times in order to verify the robustness of its responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is the sum of the ages of Mary and of Leonardo Di Caprio (as of 2023)?\"},    \n",
    "                                     config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='The sum of the ages of Mary and Leonardo Di Caprio (as of 2023) is 72.'\n",
      "[(AgentActionMessageLog(tool='INFO_ABOUT_MARY', tool_input='age', log='\\nInvoking: `INFO_ABOUT_MARY` with `age`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"age\"}', 'name': 'INFO_ABOUT_MARY'}})]), '\\n\\n24'), (AgentActionMessageLog(tool='wikipedia', tool_input='Leonardo Di Caprio', log='\\nInvoking: `wikipedia` with `Leonardo Di Caprio`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Leonardo Di Caprio\"}', 'name': 'wikipedia'}})]), 'Page: Leonardo DiCaprio\\nSummary: Leonardo Wilhelm DiCaprio (; Italian: [diˈkaːprjo]; born November 1'), (AgentActionMessageLog(tool='CALCULATE', tool_input='24 + 48', log='\\nInvoking: `CALCULATE` with `24 + 48`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"24 + 48\"}', 'name': 'CALCULATE'}})]), 'Answer: 72')]\n",
      "answer=\"Leonardo DiCaprio was born on November 11, 1974. Let's calculate the sum of the ages of Mary and Leonardo DiCaprio as of 2023.\\n\\nMary's age: 24\\nLeonardo DiCaprio's age in 2023: 2023 - 1974 = 49\\n\\nSum of their ages: 24 + 49 = 73\\n\\nTherefore, the sum of the ages of Mary and Leonardo DiCaprio (as of 2023) is 73.\"\n",
      "answer=\"Leonardo DiCaprio was born on November 11, 1974. To calculate the sum of the ages of Mary and Leonardo DiCaprio as of 2023, we need to add 24 (Mary's age) to the age of Leonardo DiCaprio in 2023.\\n\\nLet's calculate Leonardo DiCaprio's age in 2023:\\n2023 - 1974 = 49\\n\\nNow, let's calculate the sum of their ages:\\n24 (Mary's age) + 49 (Leonardo DiCaprio's age in 2023) = 73\\n\\nTherefore, the sum of the ages of Mary and Leonardo DiCaprio (as of 2023) is 73.\"\n",
      "answer=\"Leonardo DiCaprio was born on November 11, 1974. Let's calculate the sum of the ages of Mary and Leonardo DiCaprio as of 2023.\\n\\nMary's age: 24\\nLeonardo DiCaprio's age in 2023: 2023 - 1974 = 49\\n\\nSum of their ages: 24 + 49 = 73\\n\\nTherefore, the sum of the ages of Mary and Leonardo DiCaprio as of 2023 is 73.\"\n",
      "answer='I have found that Mary is 24 years old. Leonardo DiCaprio was born on November 11, 1974. As of 2023, he would be 48 years old. \\n\\nTherefore, the sum of the ages of Mary and Leonardo DiCaprio as of 2023 would be 24 + 48 = 72.'\n",
      "[(AgentActionMessageLog(tool='INFO_ABOUT_MARY', tool_input='age', log='\\nInvoking: `INFO_ABOUT_MARY` with `age`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"age\"}', 'name': 'INFO_ABOUT_MARY'}})]), '\\n\\n24'), (AgentActionMessageLog(tool='wikipedia', tool_input='Leonardo DiCaprio', log='\\nInvoking: `wikipedia` with `Leonardo DiCaprio`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Leonardo DiCaprio\"}', 'name': 'wikipedia'}})]), 'Page: Leonardo DiCaprio\\nSummary: Leonardo Wilhelm DiCaprio (; Italian: [diˈkaːprjo]; born November 1')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    response = agent_executor.invoke({\"input\": \"What is the sum of the ages of Mary and of Leonardo Di Caprio (as of 2023)?\"})\n",
    "    answer=response['output']\n",
    "    print(f\"{answer=}\")\n",
    "    if '73' not in answer:\n",
    "        print(response['intermediate_steps'])\n",
    "        wrong_answer=answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the answer to be 24+49=73. Any answer that does not contain 71 will make the code print the intermediate steps for inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now provide the agent with memory, and let's use it to evaluate the wrong answer we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "memory = ChatMessageHistory(session_id=\"test-session\")\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What is the sum of the ages of Mary and of Leonardo Di Caprio (as of 2023)?'), HumanMessage(content='I have found that Mary is 24 years old. Leonardo DiCaprio was born on November 11, 1974. As of 2023, he would be 48 years old. \\n\\nTherefore, the sum of the ages of Mary and Leonardo DiCaprio as of 2023 would be 24 + 48 = 72.')]\n",
      "I apologize for the error. Leonardo DiCaprio was born on November 11, 1974. As of 2023, he would be 49 years old. \n",
      "\n",
      "Therefore, the sum of the ages of Mary and Leonardo DiCaprio as of 2023 would be 24 + 49 = 73.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory.add_user_message(\"What is the sum of the ages of Mary and of Leonardo Di Caprio (as of 2023)?\")\n",
    "memory.add_user_message(wrong_answer)\n",
    "\n",
    "response = agent_with_chat_history.invoke({\"input\": \"Are you sure about DiCaprio's age?\"},\n",
    "                                     config={\"configurable\": {\"session_id\": \"<foo>\"}}\n",
    "                                     )\n",
    "print(response['chat_history'])\n",
    "print(response['output'])\n",
    "\n",
    "memory.messages=[] # We finally clear the memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
